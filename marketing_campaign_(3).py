# -*- coding: utf-8 -*-
"""marketing_campaign (3).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1koppoT3ctTClX3VdkEV5QO2kZ90-v7qx

---
# Ejercicio 🌮🥤

## 📍 Objetivo
Resolver la prueba técnica para el puesto de Data Analyst de la startup [ifood](https://www.ifood.com.br/) de Brasil.
<br>Esta startup se dedica al servicio de delivery de comida similar a Pedidos Ya, Rappi y Uber Eats.

## 📍 Contexto

# La empresa

Considere una empresa bien establecida que opera en el sector minorista de alimentos. Actualmente tienen alrededor
varios cientos de miles de clientes registrados y sirven a casi un millón de consumidores al año.
Venden productos de 5 categorías principales: vinos, productos cárnicos raros, frutas exóticas, especialmente
Pescados preparados y productos dulces. Estos se pueden dividir en productos premium y productos regulares.

Los clientes pueden ordenar y adquirir productos a través de 3 canales de venta: tiendas físicas, catálogos y
el sitio web de la empresa. A nivel mundial, la compañía tuvo ingresos sólidos y un resultado final saludable en el
últimos 3 años, pero las perspectivas de crecimiento de ganancias para los próximos 3 años no son prometedoras ...

**Por esta razón, se están considerando varias iniciativas estratégicas para revertir esta situación. Una es mejorar la realización de actividades de marketing, con un enfoque especial en las campañas de marketing.**

### El Departamento de Marketing

El departamento de marketing fue presionado para gastar su presupuesto anual de manera más inteligente. La CMO
percibe la importancia de tener un enfoque más cuantitativo a la hora de tomar decisiones, por lo que **se contrató a un pequeño equipo de científicos de datos con un objetivo claro en mente: construir una solución que apoye las iniciativas de marketing directo.**
<br>Deseablemente, el éxito de estas actividades demostrará el área de oportunidad y también deberan convencer a los más escépticos dentro de la empresa.

### El objetivo del equipo

Es construir un análisis para abordar el mayor beneficio para la próxima campaña de marketing, programada para el próximo mes. La nueva campaña, la sexta, tiene como objetivo vender a una nueva base de datos de clientes.

**Para construir el análisis, se desarrollo una campaña piloto que involucró 2.240 clientes. Los clientes fueron seleccionados al azar y contactados por teléfono con respecto a la adquisición del gadget. Durante los meses siguientes, los clientes que compraron el oferta fueron debidamente etiquetados.**

El coste total de la campaña de muestra fue de 6.720MU y los ingresos generado por los clientes que aceptaron la oferta fue de 3.674MU. A nivel mundial, la campaña tuvo un beneficio de -3.046MU. La tasa de éxito de la campaña fue del 15%.


## 📍 Consideraciones

- Repliquen este notebook para la resolución del ejercicio.
- Consideren las etapas: 1) Cargamos los datos, 2) Preparación de la data, 3) Clasificación, 4) Regresión y 5) Guardar un modelo.

**Son libres de decidir:**
- Cómo preparar y acondicionar el dataset.
- Pueden agregar y eliminar columnas del dataset.
- Decidir parámetros para ajustar en los modelos de clasificación y regresión.

## 📍 Consigna

- Creen un modelo de clasificación utilizando Random Forest para la columna `Response`.
- Guarden el modelo de clasificación Random forest como `rfc.pkl`.
- Creen un modelo con regresión lineal y con Random Forest + GridsearchCV para predecir la columna `Income`.
- Guardar ambos modelos de regresion en pkl `lr.pkl` y `rfr.pkl`
- Cargar proyecto en Github / Gitlab, usen git y git-lfs para los `.csv` y `.pkl`.

| **Variable**             | **Descripción**                                                                 |
|---------------------------|---------------------------------------------------------------------------------|
| AcceptedCmp1              | 1 si el cliente aceptó la oferta en la 1ª campaña, 0 en caso contrario          |
| AcceptedCmp2              | 1 si el cliente aceptó la oferta en la 2ª campaña, 0 en caso contrario          |
| AcceptedCmp3              | 1 si el cliente aceptó la oferta en la 3ª campaña, 0 en caso contrario          |
| AcceptedCmp4              | 1 si el cliente aceptó la oferta en la 4ª campaña, 0 en caso contrario          |
| AcceptedCmp5              | 1 si el cliente aceptó la oferta en la 5ª campaña, 0 en caso contrario          |
| Response (objetivo)       | 1 si el cliente aceptó la oferta en la última campaña, 0 en caso contrario      |
| Complain                  | 1 si el cliente se quejó en los últimos 2 años                                  |
| DtCustomer                | Fecha de registro del cliente con la empresa                                    |
| Education                 | Nivel educativo del cliente                                                     |
| Marital                   | Estado civil del cliente                                                        |
| Kidhome                   | Número de niños pequeños en el hogar                                            |
| Teenhome                  | Número de adolescentes en el hogar                                              |
| Income                    | Ingreso anual del hogar del cliente                                             |
| MntFishProducts           | Monto gastado en pescado en los últimos 2 años                                  |
| MntMeatProducts           | Monto gastado en carne en los últimos 2 años                                    |
| MntFruits                 | Monto gastado en frutas en los últimos 2 años                                   |
| MntSweetProducts          | Monto gastado en productos dulces en los últimos 2 años                         |
| MntWines                  | Monto gastado en vinos en los últimos 2 años                                    |
| MntGoldProds              | Monto gastado en productos de oro en los últimos 2 años                         |
| NumDealsPurchases         | Número de compras realizadas con descuento                                      |
| NumCatalogPurchases       | Número de compras realizadas mediante catálogo                                  |
| NumStorePurchases         | Número de compras realizadas directamente en tiendas                           |
| NumWebPurchases           | Número de compras realizadas en la web de la empresa                           |
| NumWebVisitsMonth         | Número de visitas a la web de la empresa en el último mes                       |
| Recency                   | Número de días desde la última compra                                           |
| Z_Revenue                 | Ingresos provenientes del nuevo dispositivo                                     |
| Z_CostContact             | Costo de contacto para la sexta campaña                                         |

## **1) Cargamos datos**
"""

!pip install funpymodeling

import pandas as pd
from funpymodeling.exploratory import freq_tbl, status

!pip install -U gdown

# Descargar todo el contenido de la carpeta compartida
!gdown --folder "https://drive.google.com/drive/folders/1gARv-63rYN3_IcpYj0hfAjVUKcW5TVFE"

!gdown --id 14LEgmlhJu0cC8X6cauKsGcH1taWAw52N -O marketing_campaign.csv

data = pd.read_csv("marketing_campaign.csv", sep=';')

data

"""## **2) Preparación de datos**"""

status(data)

"""#3) Clasificación

## 3.1) Separación de X de Y, y luego TR de TS (rutina):
"""

data_x = data.drop('Response', axis=1)
data_y = data['Response']

data_x = data_x.values
data_y = data_y.values

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.3)

"""##3.2) Creación del modelo predictivo"""

from sklearn.ensemble import RandomForestClassifier
rf=RandomForestClassifier(n_estimators=1000,random_state=99)

#  métricas de regresión
import numpy as np
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

def print_reg_metrics(y_true, y_pred):
    r2  = r2_score(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    try:
        rmse = mean_squared_error(y_true, y_pred, squared=False)
    except TypeError:
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    print("R²  :", r2)
    print("MAE :", mae)
    print("RMSE:", rmse)
    return r2, mae, rmse

""" Preprocesamiento + Modelado

"""

#  PREPROCESAMIENTO
import numpy as np
import pandas as pd


data = data.copy()

# Mapear Response si viene en texto
if data["Response"].dtype == "O":
    data["Response"] = data["Response"].astype(str).str.strip().str.lower().map({
        "yes": 1, "si": 1, "true": 1, "1": 1,
        "no": 0, "false": 0, "0": 0
    }).fillna(0).astype(int)

# Fechas -> antigüedad y eliminar columna original para que no entre a dummies
for cand in ["Dt_Customer", "Date_Customer", "Customer_Since"]:
    if cand in data.columns:
        data[cand] = pd.to_datetime(data[cand], errors="coerce")
        data["Customer_Tenure_Days"] = (data[cand].max() - data[cand]).dt.days
        data.drop(columns=[cand], inplace=True)

# Quitar columnas ID/no predictivas si están
for col in ["ID", "Id", "id", "Z_CostContact", "Z_Revenue"]:
    if col in data.columns:
        data.drop(columns=[col], inplace=True)

# Imputación simple
num_cols = data.select_dtypes(include=[np.number]).columns.tolist()
cat_cols = data.select_dtypes(exclude=[np.number]).columns.tolist()

for c in num_cols:
    data[c] = data[c].fillna(data[c].median())
for c in cat_cols:
    data[c] = data[c].astype(str).fillna("missing")

# One-hot encoding simple
data = pd.get_dummies(data, columns=cat_cols, drop_first=True)

print("Shape final:", data.shape)
data.head(3)

# === CLASIFICACIÓN: Random Forest (Response) ===
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                             f1_score, roc_auc_score, confusion_matrix, classification_report)
import pickle

X_cls = data.drop(columns=["Response"])
y_cls = data["Response"].astype(int)

# Split estratificado
Xtr_c, Xte_c, ytr_c, yte_c = train_test_split(
    X_cls, y_cls, test_size=0.3, random_state=42, stratify=y_cls
)

rfc = RandomForestClassifier(
    n_estimators=500,
    random_state=42,
    n_jobs=-1,
    class_weight="balanced"
)
rfc.fit(Xtr_c, ytr_c)

ypred_c = rfc.predict(Xte_c)
yproba_c = rfc.predict_proba(Xte_c)[:, 1]

print("=== Clasificación: Random Forest (Response) ===")
print("Accuracy :", accuracy_score(yte_c, ypred_c))
print("Precision:", precision_score(yte_c, ypred_c, zero_division=0))
print("Recall   :", recall_score(yte_c, ypred_c, zero_division=0))
print("F1       :", f1_score(yte_c, ypred_c, zero_division=0))
print("ROC-AUC  :", roc_auc_score(yte_c, yproba_c))
print("\nMatriz de confusión:\n", confusion_matrix(yte_c, ypred_c))
print("\nReporte de clasificación:\n", classification_report(yte_c, ypred_c, zero_division=0))

with open("rfc.pkl", "wb") as f:
    pickle.dump(rfc, f)
print("\n✅ Guardado rfc.pkl")

#  métricas de regresión
import numpy as np
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
def print_reg_metrics(y_true, y_pred):
    r2  = r2_score(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    try:
        rmse = mean_squared_error(y_true, y_pred, squared=False)
    except TypeError:
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    print("R²  :", r2)
    print("MAE :", mae)
    print("RMSE:", rmse)
    #return r2, mae, rmse

# === REGRESIÓN: Linear Regression (Income) ===
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# Filtrar Income válido
reg_base = data[~data["Income"].isna()].copy()

# Evitar fuga de info desde Response
X_reg_lr = reg_base.drop(columns=["Income", "Response"])
y_reg = reg_base["Income"].astype(float)

Xtr_r_lr, Xte_r_lr, ytr_r, yte_r = train_test_split(
    X_reg_lr, y_reg, test_size=0.2, random_state=42
)

pipe_lr = Pipeline(steps=[
    ("scaler", StandardScaler(with_mean=False)),  # soporta matrices dispersas
    ("model", LinearRegression())
])

pipe_lr.fit(Xtr_r_lr, ytr_r)
ypred_lr = pipe_lr.predict(Xte_r_lr)

print("=== Regresión Lineal (Income) ===")
_ = print_reg_metrics(yte_r, ypred_lr)

with open("lr.pkl", "wb") as f:
    pickle.dump(pipe_lr, f)
print("\n✅ Guardado lr.pkl")

# === REGRESIÓN: Random Forest + GridSearchCV (Income) ===
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV

X_reg_rfr = X_reg_lr.copy()
rfr = RandomForestRegressor(random_state=42, n_jobs=-1)

param_grid = {
    "n_estimators": [200, 500],
    "max_depth": [None, 10, 20],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4]
}

gcv = GridSearchCV(
    estimator=rfr,
    param_grid=param_grid,
    cv=3,
    scoring="neg_root_mean_squared_error",
    n_jobs=-1,
    verbose=1
)

gcv.fit(Xtr_r_lr, ytr_r)
best_rfr = gcv.best_estimator_

ypred_rfr = best_rfr.predict(Xte_r_lr)

print("=== Random Forest Regressor (GridSearch) ===")
print("Mejores params:", gcv.best_params_)
_ = print_reg_metrics(yte_r, ypred_rfr)

with open("rfr.pkl", "wb") as f:
    pickle.dump(best_rfr, f)
print("\n✅ Guardado rfr.pkl")

# === Importancias de variables ) ===
import pandas as pd
importances = pd.Series(rfc.feature_importances_, index=X_cls.columns).sort_values(ascending=False)
importances.head(20)

"""Análisis de las métricas de error

"""

from sklearn.dummy import DummyRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np
import pandas as pd

# Baseline con mediana (más robusto a outliers)
dum = DummyRegressor(strategy="median")
dum.fit(Xtr_r_lr, ytr_r)
y_base = dum.predict(Xte_r_lr)

def row_metrics(y_true, y_pred, name):
    r2  = r2_score(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    # sMAPE como en travel (simétrica)
    smape = 100*np.mean(2*np.abs(y_pred - y_true)/(np.abs(y_true)+np.abs(y_pred)+1e-9))
    return pd.Series({"Model": name, "R2": r2, "MAE": mae, "RMSE": rmse, "sMAPE_%": smape})

summary = pd.concat([
    row_metrics(yte_r, y_base,    "Baseline(median)"),
    row_metrics(yte_r, ypred_lr,  "LinearRegression"),
    row_metrics(yte_r, ypred_rfr, "RandomForest(Grid)")
], axis=1).T

# mejoras vs baseline
for col in ["MAE", "RMSE"]:
    summary[f"{col}_improv_vs_baseline_%"] = 100*(1 - summary[col]/summary.loc[summary["Model"]=="Baseline(median)", col].values[0])

summary.round(3)

from sklearn.model_selection import KFold, cross_val_predict

cv = KFold(n_splits=5, shuffle=True, random_state=42)

# OJO: acá usamos toda la data de regresión (X_reg_lr, y_reg) para CV
y_lr_cv  = cross_val_predict(pipe_lr,  X_reg_lr, y_reg, cv=cv, n_jobs=-1)
y_rfr_cv = cross_val_predict(best_rfr, X_reg_lr, y_reg, cv=cv, n_jobs=-1)
y_dum_cv = cross_val_predict(DummyRegressor(strategy="median"), X_reg_lr, y_reg, cv=cv, n_jobs=-1)

summary_cv = pd.concat([
    row_metrics(y_reg, y_dum_cv, "Baseline(median) CV"),
    row_metrics(y_reg, y_lr_cv,  "LinearRegression CV"),
    row_metrics(y_reg, y_rfr_cv, "RandomForest(Grid) CV")
], axis=1).T

for col in ["MAE","RMSE"]:
    summary_cv[f"{col}_improv_vs_baseline_%"] = 100*(1 - summary_cv[col]/summary_cv.loc[summary_cv["Model"]=="Baseline(median) CV", col].values[0])

summary_cv.round(3)

import matplotlib.pyplot as plt
import numpy as np

res_lr  = yte_r - ypred_lr
res_rfr = yte_r - ypred_rfr

# recorte 1–99% para que no dominen outliers
qlo, qhi = np.percentile(np.r_[res_lr, res_rfr], [1, 99])
bins = np.linspace(qlo, qhi, 40)

plt.figure(figsize=(6,4))
plt.hist(np.clip(res_lr,  qlo, qhi), bins=bins, alpha=0.6, label="LR")
plt.hist(np.clip(res_rfr, qlo, qhi), bins=bins, alpha=0.6, label="RF")
plt.title("Distribución de residuos (recorte 1–99%)")
plt.legend(); plt.show()

# Residuos vs predicción (recorte en ejes)
x = np.r_[ypred_lr, ypred_rfr]
y = np.r_[res_lr,  res_rfr]
xlo, xhi = np.percentile(x, [1,99])
ylo, yhi = np.percentile(y, [1,99])

plt.figure(figsize=(6,4))
plt.scatter(np.clip(ypred_lr,  xlo, xhi), np.clip(res_lr,  ylo, yhi), s=10, alpha=0.5, label="LR")
plt.scatter(np.clip(ypred_rfr, xlo, xhi), np.clip(res_rfr, ylo, yhi), s=10, alpha=0.5, label="RF")
plt.axhline(0, color="k", lw=1)
plt.title("Residuos vs Predicción (recorte 1–99%)")
plt.legend(); plt.show()

"""1 Nube alrededor de 0: en promedio no hay gran sesgo global.

2 Heteroscedasticidad: a medida que la predicción aumenta (ingresos altos), la dispersión de los errores crece. Es normal en ingresos: los errores absolutos tienden a ser mayores en valores grandes.

3 LR (azul) vs RF (verde):

LR muestra un patrón típico de “regresión a la media”:

4 en predicciones más bajas (~20k–45k) hay muchos residuos positivos ⇒ subestima esos ingresos;

5 en predicciones altas (>60k) aparecen más negativos ⇒ sobreestima arriba.

6 RF está más centrado y con menor patrón, aunque también sufre algo de heteroscedasticidad. Esto cuadra con tus métricas (RF con MAE/RMSE menores).
"""

from sklearn.compose import TransformedTargetRegressor
pipe_lr_log = Pipeline([("scaler", StandardScaler(with_mean=False)), ("model", LinearRegression())])
ttr_lr  = TransformedTargetRegressor(regressor=pipe_lr_log, func=np.log1p, inverse_func=np.expm1)
ttr_rfr = TransformedTargetRegressor(regressor=best_rfr,    func=np.log1p, inverse_func=np.expm1)

from yellowbrick.classifier import DiscriminationThreshold
import matplotlib.pyplot as plt

# Estimá parámetros económicos
costo_contacto = 3.0      # MU por contacto
ingreso_aceptante = 10.9  # MU por aceptación (3674 MU / 336 aceptantes ≈ 10.9)
break_even = costo_contacto / ingreso_aceptante  # 0.27

viz = DiscriminationThreshold(rfc)  # rfc = RandomForestClassifier ya ajustado
viz.fit(Xtr_c, ytr_c)               # ajusta en train
viz.score(Xte_c, yte_c)             # evalúa en test
ax = viz.show()

# Marcar el umbral de break-even
try:
    ax.axvline(break_even, linestyle="--")
    ax.text(break_even+0.01, 0.05, f"break-even ≈ {break_even:.2f}", rotation=90)
    plt.show()
except Exception:
    pass

"""Las curvas muestran cómo cambian precision, recall y F1 al mover el umbral.

La línea punteada marca el break-even económico (≈ 0.26 = costo/ingreso).

Visualmente, la zona buena está alrededor de 0.26–0.30 (F1 alto y precision/recall razonables).
"""

import numpy as np

proba = rfc.predict_proba(Xte_c)[:, 1]  # probabilidades en test

def beneficio_esperado(th):
    # contactamos si proba >= th
    mask = proba >= th
    # beneficio esperado individual: p*ingreso - costo_contacto (si contacto)
    return np.sum(proba[mask]*ingreso_aceptante - costo_contacto)

thresholds = np.linspace(0.01, 0.99, 99)
beneficios = np.array([beneficio_esperado(t) for t in thresholds])

t_opt = thresholds[np.argmax(beneficios)]
best_benefit = beneficios.max()

print(f"Umbral óptimo por beneficio esperado: {t_opt:.3f}")
print(f"Beneficio esperado en test: {best_benefit:.2f} MU")

# (Opcional) ver 5 mejores
top = np.argsort(beneficios)[-5:][::-1]
for i in top:
    print(f"t={thresholds[i]:.3f}  beneficio={beneficios[i]:.2f} MU")

# (Opcional) si querés ver métricas en ese umbral:
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
pred_opt = (proba >= t_opt).astype(int)
print("\nPrec:", precision_score(yte_c, pred_opt, zero_division=0),
      " Rec:", recall_score(yte_c, pred_opt, zero_division=0),
      " F1:",  f1_score(yte_c, pred_opt, zero_division=0))
print("Matriz de confusión (t*):\n", confusion_matrix(yte_c, pred_opt))

"""Umbral óptimo = 0.27 y beneficio esperado ≈ 178 MU.

Con t=0.27:

Precisión ≈ 0.57 (de los contactados, 57% aceptan).

Recall ≈ 0.56 (recuperás ~56% de todos los que aceptarían).

Matriz [[529, 43], [44, 56]] → contactás 99 personas (43 FP + 56 TP) sobre 672 → queue rate ≈ 14.7%.

"""

from sklearn.calibration import CalibratedClassifierCV

rfc_cal = CalibratedClassifierCV(
    estimator=RandomForestClassifier(
        n_estimators=500, random_state=42, class_weight="balanced", n_jobs=-1
    ),
    method="isotonic", cv=3
)
rfc_cal.fit(Xtr_c, ytr_c)

proba_cal = rfc_cal.predict_proba(Xte_c)[:,1]
# Repetí tu loop de beneficio con proba_cal en lugar de proba

# Calculate and display the optimal threshold and performance metrics for the calibrated model

proba_cal = rfc_cal.predict_proba(Xte_c)[:, 1]  # calibrated probabilities in test

def beneficio_esperado_cal(th):
    # contactamos si proba_cal >= th
    mask = proba_cal >= th
    # beneficio esperado individual: p*ingreso - costo_contacto (si contacto)
    return np.sum(proba_cal[mask]*ingreso_aceptante - costo_contacto)

thresholds_cal = np.linspace(0.01, 0.99, 99)
beneficios_cal = np.array([beneficio_esperado_cal(t) for t in thresholds_cal])

t_opt_cal = thresholds_cal[np.argmax(beneficios_cal)]
best_benefit_cal = beneficios_cal.max()

print(f"Umbral óptimo por beneficio esperado (Calibrated): {t_opt_cal:.3f}")
print(f"Beneficio esperado en test (Calibrated): {best_benefit_cal:.2f} MU")

# (Opcional) ver 5 mejores
top_cal = np.argsort(beneficios_cal)[-5:][::-1]
print("\nTop 5 thresholds and benefits (Calibrated):")
for i in top_cal:
    print(f"t={thresholds_cal[i]:.3f}  beneficio={beneficios_cal[i]:.2f} MU")

# (Opcional) si querés ver métricas en ese umbral:
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
pred_opt_cal = (proba_cal >= t_opt_cal).astype(int)
print("\nMetrics at optimal threshold (Calibrated):")
print("Prec:", precision_score(yte_c, pred_opt_cal, zero_division=0),
      " Rec:", recall_score(yte_c, pred_opt_cal, zero_division=0),
      " F1:",  f1_score(yte_c, pred_opt_cal, zero_division=0))
print("Matriz de confusión (t* Calibrated):\n", confusion_matrix(yte_c, pred_opt_cal))

"""
Entrega en Git (con LFS)

**Pasos**  
1) Asegurate de tener `git` y `git-lfs` instalados.  
2) Parate en la carpeta del repo (donde está este notebook y los `.pkl`).  
3) Ejecutá la celda de abajo.  
   - Si no tenés remoto, agregalo con: `git remote add origin <URL-del-repo>`  
   - Si tu rama no es `main`, reemplazá `main` por tu rama.
"""

!git lfs install
!git lfs track "*.csv" "*.pkl"
!git add .gitattributes

# Agregamos notebook y modelos
!git add marketing_campaign.ipynb rfc.pkl lr.pkl rfr.pkl

# Commit y push
!git commit -m "iFood challenge: RF clasificación (Response) + LR & RF(Grid) regresión (Income) + modelos .pkl"
!git push origin main