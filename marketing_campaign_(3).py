# -*- coding: utf-8 -*-
"""marketing_campaign (3).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1koppoT3ctTClX3VdkEV5QO2kZ90-v7qx

---
# Ejercicio üåÆü•§

## üìç Objetivo
Resolver la prueba t√©cnica para el puesto de Data Analyst de la startup [ifood](https://www.ifood.com.br/) de Brasil.
<br>Esta startup se dedica al servicio de delivery de comida similar a Pedidos Ya, Rappi y Uber Eats.

## üìç Contexto

# La empresa

Considere una empresa bien establecida que opera en el sector minorista de alimentos. Actualmente tienen alrededor
varios cientos de miles de clientes registrados y sirven a casi un mill√≥n de consumidores al a√±o.
Venden productos de 5 categor√≠as principales: vinos, productos c√°rnicos raros, frutas ex√≥ticas, especialmente
Pescados preparados y productos dulces. Estos se pueden dividir en productos premium y productos regulares.

Los clientes pueden ordenar y adquirir productos a trav√©s de 3 canales de venta: tiendas f√≠sicas, cat√°logos y
el sitio web de la empresa. A nivel mundial, la compa√±√≠a tuvo ingresos s√≥lidos y un resultado final saludable en el
√∫ltimos 3 a√±os, pero las perspectivas de crecimiento de ganancias para los pr√≥ximos 3 a√±os no son prometedoras ...

**Por esta raz√≥n, se est√°n considerando varias iniciativas estrat√©gicas para revertir esta situaci√≥n. Una es mejorar la realizaci√≥n de actividades de marketing, con un enfoque especial en las campa√±as de marketing.**

### El Departamento de Marketing

El departamento de marketing fue presionado para gastar su presupuesto anual de manera m√°s inteligente. La CMO
percibe la importancia de tener un enfoque m√°s cuantitativo a la hora de tomar decisiones, por lo que **se contrat√≥ a un peque√±o equipo de cient√≠ficos de datos con un objetivo claro en mente: construir una soluci√≥n que apoye las iniciativas de marketing directo.**
<br>Deseablemente, el √©xito de estas actividades demostrar√° el √°rea de oportunidad y tambi√©n deberan convencer a los m√°s esc√©pticos dentro de la empresa.

### El objetivo del equipo

Es construir un an√°lisis para abordar el mayor beneficio para la pr√≥xima campa√±a de marketing, programada para el pr√≥ximo mes. La nueva campa√±a, la sexta, tiene como objetivo vender a una nueva base de datos de clientes.

**Para construir el an√°lisis, se desarrollo una campa√±a piloto que involucr√≥ 2.240 clientes. Los clientes fueron seleccionados al azar y contactados por tel√©fono con respecto a la adquisici√≥n del gadget. Durante los meses siguientes, los clientes que compraron el oferta fueron debidamente etiquetados.**

El coste total de la campa√±a de muestra fue de 6.720MU y los ingresos generado por los clientes que aceptaron la oferta fue de 3.674MU. A nivel mundial, la campa√±a tuvo un beneficio de -3.046MU. La tasa de √©xito de la campa√±a fue del 15%.


## üìç Consideraciones

- Repliquen este notebook para la resoluci√≥n del ejercicio.
- Consideren las etapas: 1) Cargamos los datos, 2) Preparaci√≥n de la data, 3) Clasificaci√≥n, 4) Regresi√≥n y 5) Guardar un modelo.

**Son libres de decidir:**
- C√≥mo preparar y acondicionar el dataset.
- Pueden agregar y eliminar columnas del dataset.
- Decidir par√°metros para ajustar en los modelos de clasificaci√≥n y regresi√≥n.

## üìç Consigna

- Creen un modelo de clasificaci√≥n utilizando Random Forest para la columna `Response`.
- Guarden el modelo de clasificaci√≥n Random forest como `rfc.pkl`.
- Creen un modelo con regresi√≥n lineal y con Random Forest + GridsearchCV para predecir la columna `Income`.
- Guardar ambos modelos de regresion en pkl `lr.pkl` y `rfr.pkl`
- Cargar proyecto en Github / Gitlab, usen git y git-lfs para los `.csv` y `.pkl`.

| **Variable**             | **Descripci√≥n**                                                                 |
|---------------------------|---------------------------------------------------------------------------------|
| AcceptedCmp1              | 1 si el cliente acept√≥ la oferta en la 1¬™ campa√±a, 0 en caso contrario          |
| AcceptedCmp2              | 1 si el cliente acept√≥ la oferta en la 2¬™ campa√±a, 0 en caso contrario          |
| AcceptedCmp3              | 1 si el cliente acept√≥ la oferta en la 3¬™ campa√±a, 0 en caso contrario          |
| AcceptedCmp4              | 1 si el cliente acept√≥ la oferta en la 4¬™ campa√±a, 0 en caso contrario          |
| AcceptedCmp5              | 1 si el cliente acept√≥ la oferta en la 5¬™ campa√±a, 0 en caso contrario          |
| Response (objetivo)       | 1 si el cliente acept√≥ la oferta en la √∫ltima campa√±a, 0 en caso contrario      |
| Complain                  | 1 si el cliente se quej√≥ en los √∫ltimos 2 a√±os                                  |
| DtCustomer                | Fecha de registro del cliente con la empresa                                    |
| Education                 | Nivel educativo del cliente                                                     |
| Marital                   | Estado civil del cliente                                                        |
| Kidhome                   | N√∫mero de ni√±os peque√±os en el hogar                                            |
| Teenhome                  | N√∫mero de adolescentes en el hogar                                              |
| Income                    | Ingreso anual del hogar del cliente                                             |
| MntFishProducts           | Monto gastado en pescado en los √∫ltimos 2 a√±os                                  |
| MntMeatProducts           | Monto gastado en carne en los √∫ltimos 2 a√±os                                    |
| MntFruits                 | Monto gastado en frutas en los √∫ltimos 2 a√±os                                   |
| MntSweetProducts          | Monto gastado en productos dulces en los √∫ltimos 2 a√±os                         |
| MntWines                  | Monto gastado en vinos en los √∫ltimos 2 a√±os                                    |
| MntGoldProds              | Monto gastado en productos de oro en los √∫ltimos 2 a√±os                         |
| NumDealsPurchases         | N√∫mero de compras realizadas con descuento                                      |
| NumCatalogPurchases       | N√∫mero de compras realizadas mediante cat√°logo                                  |
| NumStorePurchases         | N√∫mero de compras realizadas directamente en tiendas                           |
| NumWebPurchases           | N√∫mero de compras realizadas en la web de la empresa                           |
| NumWebVisitsMonth         | N√∫mero de visitas a la web de la empresa en el √∫ltimo mes                       |
| Recency                   | N√∫mero de d√≠as desde la √∫ltima compra                                           |
| Z_Revenue                 | Ingresos provenientes del nuevo dispositivo                                     |
| Z_CostContact             | Costo de contacto para la sexta campa√±a                                         |

## **1) Cargamos datos**
"""

!pip install funpymodeling

import pandas as pd
from funpymodeling.exploratory import freq_tbl, status

!pip install -U gdown

# Descargar todo el contenido de la carpeta compartida
!gdown --folder "https://drive.google.com/drive/folders/1gARv-63rYN3_IcpYj0hfAjVUKcW5TVFE"

!gdown --id 14LEgmlhJu0cC8X6cauKsGcH1taWAw52N -O marketing_campaign.csv

data = pd.read_csv("marketing_campaign.csv", sep=';')

data

"""## **2) Preparaci√≥n de datos**"""

status(data)

"""#3) Clasificaci√≥n

## 3.1) Separaci√≥n de X de Y, y luego TR de TS (rutina):
"""

data_x = data.drop('Response', axis=1)
data_y = data['Response']

data_x = data_x.values
data_y = data_y.values

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.3)

"""##3.2) Creaci√≥n del modelo predictivo"""

from sklearn.ensemble import RandomForestClassifier
rf=RandomForestClassifier(n_estimators=1000,random_state=99)

#  m√©tricas de regresi√≥n
import numpy as np
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

def print_reg_metrics(y_true, y_pred):
    r2  = r2_score(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    try:
        rmse = mean_squared_error(y_true, y_pred, squared=False)
    except TypeError:
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    print("R¬≤  :", r2)
    print("MAE :", mae)
    print("RMSE:", rmse)
    return r2, mae, rmse

""" Preprocesamiento + Modelado

"""

#  PREPROCESAMIENTO
import numpy as np
import pandas as pd


data = data.copy()

# Mapear Response si viene en texto
if data["Response"].dtype == "O":
    data["Response"] = data["Response"].astype(str).str.strip().str.lower().map({
        "yes": 1, "si": 1, "true": 1, "1": 1,
        "no": 0, "false": 0, "0": 0
    }).fillna(0).astype(int)

# Fechas -> antig√ºedad y eliminar columna original para que no entre a dummies
for cand in ["Dt_Customer", "Date_Customer", "Customer_Since"]:
    if cand in data.columns:
        data[cand] = pd.to_datetime(data[cand], errors="coerce")
        data["Customer_Tenure_Days"] = (data[cand].max() - data[cand]).dt.days
        data.drop(columns=[cand], inplace=True)

# Quitar columnas ID/no predictivas si est√°n
for col in ["ID", "Id", "id", "Z_CostContact", "Z_Revenue"]:
    if col in data.columns:
        data.drop(columns=[col], inplace=True)

# Imputaci√≥n simple
num_cols = data.select_dtypes(include=[np.number]).columns.tolist()
cat_cols = data.select_dtypes(exclude=[np.number]).columns.tolist()

for c in num_cols:
    data[c] = data[c].fillna(data[c].median())
for c in cat_cols:
    data[c] = data[c].astype(str).fillna("missing")

# One-hot encoding simple
data = pd.get_dummies(data, columns=cat_cols, drop_first=True)

print("Shape final:", data.shape)
data.head(3)

# === CLASIFICACI√ìN: Random Forest (Response) ===
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                             f1_score, roc_auc_score, confusion_matrix, classification_report)
import pickle

X_cls = data.drop(columns=["Response"])
y_cls = data["Response"].astype(int)

# Split estratificado
Xtr_c, Xte_c, ytr_c, yte_c = train_test_split(
    X_cls, y_cls, test_size=0.3, random_state=42, stratify=y_cls
)

rfc = RandomForestClassifier(
    n_estimators=500,
    random_state=42,
    n_jobs=-1,
    class_weight="balanced"
)
rfc.fit(Xtr_c, ytr_c)

ypred_c = rfc.predict(Xte_c)
yproba_c = rfc.predict_proba(Xte_c)[:, 1]

print("=== Clasificaci√≥n: Random Forest (Response) ===")
print("Accuracy :", accuracy_score(yte_c, ypred_c))
print("Precision:", precision_score(yte_c, ypred_c, zero_division=0))
print("Recall   :", recall_score(yte_c, ypred_c, zero_division=0))
print("F1       :", f1_score(yte_c, ypred_c, zero_division=0))
print("ROC-AUC  :", roc_auc_score(yte_c, yproba_c))
print("\nMatriz de confusi√≥n:\n", confusion_matrix(yte_c, ypred_c))
print("\nReporte de clasificaci√≥n:\n", classification_report(yte_c, ypred_c, zero_division=0))

with open("rfc.pkl", "wb") as f:
    pickle.dump(rfc, f)
print("\n‚úÖ Guardado rfc.pkl")

#  m√©tricas de regresi√≥n
import numpy as np
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
def print_reg_metrics(y_true, y_pred):
    r2  = r2_score(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    try:
        rmse = mean_squared_error(y_true, y_pred, squared=False)
    except TypeError:
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    print("R¬≤  :", r2)
    print("MAE :", mae)
    print("RMSE:", rmse)
    #return r2, mae, rmse

# === REGRESI√ìN: Linear Regression (Income) ===
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# Filtrar Income v√°lido
reg_base = data[~data["Income"].isna()].copy()

# Evitar fuga de info desde Response
X_reg_lr = reg_base.drop(columns=["Income", "Response"])
y_reg = reg_base["Income"].astype(float)

Xtr_r_lr, Xte_r_lr, ytr_r, yte_r = train_test_split(
    X_reg_lr, y_reg, test_size=0.2, random_state=42
)

pipe_lr = Pipeline(steps=[
    ("scaler", StandardScaler(with_mean=False)),  # soporta matrices dispersas
    ("model", LinearRegression())
])

pipe_lr.fit(Xtr_r_lr, ytr_r)
ypred_lr = pipe_lr.predict(Xte_r_lr)

print("=== Regresi√≥n Lineal (Income) ===")
_ = print_reg_metrics(yte_r, ypred_lr)

with open("lr.pkl", "wb") as f:
    pickle.dump(pipe_lr, f)
print("\n‚úÖ Guardado lr.pkl")

# === REGRESI√ìN: Random Forest + GridSearchCV (Income) ===
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV

X_reg_rfr = X_reg_lr.copy()
rfr = RandomForestRegressor(random_state=42, n_jobs=-1)

param_grid = {
    "n_estimators": [200, 500],
    "max_depth": [None, 10, 20],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4]
}

gcv = GridSearchCV(
    estimator=rfr,
    param_grid=param_grid,
    cv=3,
    scoring="neg_root_mean_squared_error",
    n_jobs=-1,
    verbose=1
)

gcv.fit(Xtr_r_lr, ytr_r)
best_rfr = gcv.best_estimator_

ypred_rfr = best_rfr.predict(Xte_r_lr)

print("=== Random Forest Regressor (GridSearch) ===")
print("Mejores params:", gcv.best_params_)
_ = print_reg_metrics(yte_r, ypred_rfr)

with open("rfr.pkl", "wb") as f:
    pickle.dump(best_rfr, f)
print("\n‚úÖ Guardado rfr.pkl")

# === Importancias de variables ) ===
import pandas as pd
importances = pd.Series(rfc.feature_importances_, index=X_cls.columns).sort_values(ascending=False)
importances.head(20)

"""An√°lisis de las m√©tricas de error

"""

from sklearn.dummy import DummyRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np
import pandas as pd

# Baseline con mediana (m√°s robusto a outliers)
dum = DummyRegressor(strategy="median")
dum.fit(Xtr_r_lr, ytr_r)
y_base = dum.predict(Xte_r_lr)

def row_metrics(y_true, y_pred, name):
    r2  = r2_score(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    # sMAPE como en travel (sim√©trica)
    smape = 100*np.mean(2*np.abs(y_pred - y_true)/(np.abs(y_true)+np.abs(y_pred)+1e-9))
    return pd.Series({"Model": name, "R2": r2, "MAE": mae, "RMSE": rmse, "sMAPE_%": smape})

summary = pd.concat([
    row_metrics(yte_r, y_base,    "Baseline(median)"),
    row_metrics(yte_r, ypred_lr,  "LinearRegression"),
    row_metrics(yte_r, ypred_rfr, "RandomForest(Grid)")
], axis=1).T

# mejoras vs baseline
for col in ["MAE", "RMSE"]:
    summary[f"{col}_improv_vs_baseline_%"] = 100*(1 - summary[col]/summary.loc[summary["Model"]=="Baseline(median)", col].values[0])

summary.round(3)

from sklearn.model_selection import KFold, cross_val_predict

cv = KFold(n_splits=5, shuffle=True, random_state=42)

# OJO: ac√° usamos toda la data de regresi√≥n (X_reg_lr, y_reg) para CV
y_lr_cv  = cross_val_predict(pipe_lr,  X_reg_lr, y_reg, cv=cv, n_jobs=-1)
y_rfr_cv = cross_val_predict(best_rfr, X_reg_lr, y_reg, cv=cv, n_jobs=-1)
y_dum_cv = cross_val_predict(DummyRegressor(strategy="median"), X_reg_lr, y_reg, cv=cv, n_jobs=-1)

summary_cv = pd.concat([
    row_metrics(y_reg, y_dum_cv, "Baseline(median) CV"),
    row_metrics(y_reg, y_lr_cv,  "LinearRegression CV"),
    row_metrics(y_reg, y_rfr_cv, "RandomForest(Grid) CV")
], axis=1).T

for col in ["MAE","RMSE"]:
    summary_cv[f"{col}_improv_vs_baseline_%"] = 100*(1 - summary_cv[col]/summary_cv.loc[summary_cv["Model"]=="Baseline(median) CV", col].values[0])

summary_cv.round(3)

import matplotlib.pyplot as plt
import numpy as np

res_lr  = yte_r - ypred_lr
res_rfr = yte_r - ypred_rfr

# recorte 1‚Äì99% para que no dominen outliers
qlo, qhi = np.percentile(np.r_[res_lr, res_rfr], [1, 99])
bins = np.linspace(qlo, qhi, 40)

plt.figure(figsize=(6,4))
plt.hist(np.clip(res_lr,  qlo, qhi), bins=bins, alpha=0.6, label="LR")
plt.hist(np.clip(res_rfr, qlo, qhi), bins=bins, alpha=0.6, label="RF")
plt.title("Distribuci√≥n de residuos (recorte 1‚Äì99%)")
plt.legend(); plt.show()

# Residuos vs predicci√≥n (recorte en ejes)
x = np.r_[ypred_lr, ypred_rfr]
y = np.r_[res_lr,  res_rfr]
xlo, xhi = np.percentile(x, [1,99])
ylo, yhi = np.percentile(y, [1,99])

plt.figure(figsize=(6,4))
plt.scatter(np.clip(ypred_lr,  xlo, xhi), np.clip(res_lr,  ylo, yhi), s=10, alpha=0.5, label="LR")
plt.scatter(np.clip(ypred_rfr, xlo, xhi), np.clip(res_rfr, ylo, yhi), s=10, alpha=0.5, label="RF")
plt.axhline(0, color="k", lw=1)
plt.title("Residuos vs Predicci√≥n (recorte 1‚Äì99%)")
plt.legend(); plt.show()

"""1 Nube alrededor de 0: en promedio no hay gran sesgo global.

2 Heteroscedasticidad: a medida que la predicci√≥n aumenta (ingresos altos), la dispersi√≥n de los errores crece. Es normal en ingresos: los errores absolutos tienden a ser mayores en valores grandes.

3 LR (azul) vs RF (verde):

LR muestra un patr√≥n t√≠pico de ‚Äúregresi√≥n a la media‚Äù:

4 en predicciones m√°s bajas (~20k‚Äì45k) hay muchos residuos positivos ‚áí subestima esos ingresos;

5 en predicciones altas (>60k) aparecen m√°s negativos ‚áí sobreestima arriba.

6 RF est√° m√°s centrado y con menor patr√≥n, aunque tambi√©n sufre algo de heteroscedasticidad. Esto cuadra con tus m√©tricas (RF con MAE/RMSE menores).
"""

from sklearn.compose import TransformedTargetRegressor
pipe_lr_log = Pipeline([("scaler", StandardScaler(with_mean=False)), ("model", LinearRegression())])
ttr_lr  = TransformedTargetRegressor(regressor=pipe_lr_log, func=np.log1p, inverse_func=np.expm1)
ttr_rfr = TransformedTargetRegressor(regressor=best_rfr,    func=np.log1p, inverse_func=np.expm1)

from yellowbrick.classifier import DiscriminationThreshold
import matplotlib.pyplot as plt

# Estim√° par√°metros econ√≥micos
costo_contacto = 3.0      # MU por contacto
ingreso_aceptante = 10.9  # MU por aceptaci√≥n (3674 MU / 336 aceptantes ‚âà 10.9)
break_even = costo_contacto / ingreso_aceptante  # 0.27

viz = DiscriminationThreshold(rfc)  # rfc = RandomForestClassifier ya ajustado
viz.fit(Xtr_c, ytr_c)               # ajusta en train
viz.score(Xte_c, yte_c)             # eval√∫a en test
ax = viz.show()

# Marcar el umbral de break-even
try:
    ax.axvline(break_even, linestyle="--")
    ax.text(break_even+0.01, 0.05, f"break-even ‚âà {break_even:.2f}", rotation=90)
    plt.show()
except Exception:
    pass

"""Las curvas muestran c√≥mo cambian precision, recall y F1 al mover el umbral.

La l√≠nea punteada marca el break-even econ√≥mico (‚âà 0.26 = costo/ingreso).

Visualmente, la zona buena est√° alrededor de 0.26‚Äì0.30 (F1 alto y precision/recall razonables).
"""

import numpy as np

proba = rfc.predict_proba(Xte_c)[:, 1]  # probabilidades en test

def beneficio_esperado(th):
    # contactamos si proba >= th
    mask = proba >= th
    # beneficio esperado individual: p*ingreso - costo_contacto (si contacto)
    return np.sum(proba[mask]*ingreso_aceptante - costo_contacto)

thresholds = np.linspace(0.01, 0.99, 99)
beneficios = np.array([beneficio_esperado(t) for t in thresholds])

t_opt = thresholds[np.argmax(beneficios)]
best_benefit = beneficios.max()

print(f"Umbral √≥ptimo por beneficio esperado: {t_opt:.3f}")
print(f"Beneficio esperado en test: {best_benefit:.2f} MU")

# (Opcional) ver 5 mejores
top = np.argsort(beneficios)[-5:][::-1]
for i in top:
    print(f"t={thresholds[i]:.3f}  beneficio={beneficios[i]:.2f} MU")

# (Opcional) si quer√©s ver m√©tricas en ese umbral:
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
pred_opt = (proba >= t_opt).astype(int)
print("\nPrec:", precision_score(yte_c, pred_opt, zero_division=0),
      " Rec:", recall_score(yte_c, pred_opt, zero_division=0),
      " F1:",  f1_score(yte_c, pred_opt, zero_division=0))
print("Matriz de confusi√≥n (t*):\n", confusion_matrix(yte_c, pred_opt))

"""Umbral √≥ptimo = 0.27 y beneficio esperado ‚âà 178 MU.

Con t=0.27:

Precisi√≥n ‚âà 0.57 (de los contactados, 57% aceptan).

Recall ‚âà 0.56 (recuper√°s ~56% de todos los que aceptar√≠an).

Matriz [[529, 43], [44, 56]] ‚Üí contact√°s 99 personas (43 FP + 56 TP) sobre 672 ‚Üí queue rate ‚âà 14.7%.

"""

from sklearn.calibration import CalibratedClassifierCV

rfc_cal = CalibratedClassifierCV(
    estimator=RandomForestClassifier(
        n_estimators=500, random_state=42, class_weight="balanced", n_jobs=-1
    ),
    method="isotonic", cv=3
)
rfc_cal.fit(Xtr_c, ytr_c)

proba_cal = rfc_cal.predict_proba(Xte_c)[:,1]
# Repet√≠ tu loop de beneficio con proba_cal en lugar de proba

# Calculate and display the optimal threshold and performance metrics for the calibrated model

proba_cal = rfc_cal.predict_proba(Xte_c)[:, 1]  # calibrated probabilities in test

def beneficio_esperado_cal(th):
    # contactamos si proba_cal >= th
    mask = proba_cal >= th
    # beneficio esperado individual: p*ingreso - costo_contacto (si contacto)
    return np.sum(proba_cal[mask]*ingreso_aceptante - costo_contacto)

thresholds_cal = np.linspace(0.01, 0.99, 99)
beneficios_cal = np.array([beneficio_esperado_cal(t) for t in thresholds_cal])

t_opt_cal = thresholds_cal[np.argmax(beneficios_cal)]
best_benefit_cal = beneficios_cal.max()

print(f"Umbral √≥ptimo por beneficio esperado (Calibrated): {t_opt_cal:.3f}")
print(f"Beneficio esperado en test (Calibrated): {best_benefit_cal:.2f} MU")

# (Opcional) ver 5 mejores
top_cal = np.argsort(beneficios_cal)[-5:][::-1]
print("\nTop 5 thresholds and benefits (Calibrated):")
for i in top_cal:
    print(f"t={thresholds_cal[i]:.3f}  beneficio={beneficios_cal[i]:.2f} MU")

# (Opcional) si quer√©s ver m√©tricas en ese umbral:
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
pred_opt_cal = (proba_cal >= t_opt_cal).astype(int)
print("\nMetrics at optimal threshold (Calibrated):")
print("Prec:", precision_score(yte_c, pred_opt_cal, zero_division=0),
      " Rec:", recall_score(yte_c, pred_opt_cal, zero_division=0),
      " F1:",  f1_score(yte_c, pred_opt_cal, zero_division=0))
print("Matriz de confusi√≥n (t* Calibrated):\n", confusion_matrix(yte_c, pred_opt_cal))

"""
Entrega en Git (con LFS)

**Pasos**  
1) Asegurate de tener `git` y `git-lfs` instalados.  
2) Parate en la carpeta del repo (donde est√° este notebook y los `.pkl`).  
3) Ejecut√° la celda de abajo.  
   - Si no ten√©s remoto, agregalo con: `git remote add origin <URL-del-repo>`  
   - Si tu rama no es `main`, reemplaz√° `main` por tu rama.
"""

!git lfs install
!git lfs track "*.csv" "*.pkl"
!git add .gitattributes

# Agregamos notebook y modelos
!git add marketing_campaign.ipynb rfc.pkl lr.pkl rfr.pkl

# Commit y push
!git commit -m "iFood challenge: RF clasificaci√≥n (Response) + LR & RF(Grid) regresi√≥n (Income) + modelos .pkl"
!git push origin main